ğŸ“ Memory VDB â€” User Goals, Requirements, and Preferences (v1.0)

Owner: [You]
System: Memory VDB â€” A self-evolving AI memory engine using GPT, LLaMA, and FAISS

--------------------------------------------------------
ğŸ¯ PRIMARY GOALS
--------------------------------------------------------

- Build a durable, token-efficient long-term memory system that:
  - Stores, reflects on, and evolves memory over time
  - Is modular and local-first (GPT as orchestrator, LLaMA for local parsing)
  - Requires zero manual file naming or folder organization

- Enable the AI to:
  - Know what it knows
  - Update memory intelligently
  - Never forget past logic
  - Avoid redundant or corrupted memory

- Eventually create a system that can:
  - Parse all past conversations
  - Generate memory structures on the fly
  - Reflect on memory contextually before answering or acting

--------------------------------------------------------
ğŸ§± SYSTEM REQUIREMENTS
--------------------------------------------------------

âœ… Memory is cumulative and additive â€” no destructive overwrites
âœ… Smart deduplication â€” skip truly identical info, but include new context/POV
âœ… All changes are logged (memory_changelog.json + per-file logs)
âœ… Modular file structure â€” all paths managed via `paths.json`
âœ… Deduplication handled by `input_hash.json` (pre-LLaMA) and `ingest_hash.json` (pre-FAISS)
âœ… Archive all previous versions before replacing
âœ… Retry failed operations with DAG logic using `task_queue.json`

--------------------------------------------------------
ğŸ› ï¸ PREFERENCES FOR ALL SCRIPTS & FLOWS
--------------------------------------------------------

âš™ï¸ **Modularity First**
- All components should be swappable or testable in isolation
- No hardcoded paths â€” everything uses `paths.json`

ğŸ’¾ **File Safety**
- Never overwrite existing memory unless archive and diff are handled
- Use `archive_log.json` and per-file timestamped backups

ğŸ” **Test Mode / Mock Runs**
- Scripts should support `--test_run` or `--dry_run`
- Test runs must not write memory or upload files
- Test runs should still log what *would* have happened

ğŸ“‹ **Logging**
- Print a summary at the end: success/fail, what happened, suggestions if something failed
- Donâ€™t print every step unless debugging
- Always log task attempts (even test ones) in `task_queue.json`

ğŸ§ª **Validation & Safety**
- All LLaMA outputs must be schema-validated before saving
- Deduplication must occur BEFORE any write or upload
- Task failure must never go unlogged

--------------------------------------------------------
ğŸ“¡ BOT INTEGRATION STYLE
--------------------------------------------------------

- Donâ€™t ask vague or open-ended questions
- No rehashing unless context is lost
- Give clear checkpoints and options
- Always highlight risks or pending decisions
- Minimize token use where possible (no fluff)
- Treat every task like a modular component
- Summarize plans before building
- Output should be copy/paste ready

--------------------------------------------------------
ğŸ”œ FUTURE FEATURES TO SUPPORT
--------------------------------------------------------

- Smart memory diffing (semantic)
- Agent memory awareness and reflection
- Full query support for GPT to search and reference memory
- Background scheduling for retry/ingest
- Self-updating summaries based on memory file changes

--------------------------------------------------------
ğŸ§  MEMORY VDB â€” CONTEXT PASSPHRASE
Use this when beginning a new session:

â€œContinue building the Memory VDB system. I have uploaded your backend files. You already know my goals and preferences.â€
