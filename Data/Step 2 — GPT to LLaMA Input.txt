ğŸ§© Step 2 â€” GPT Writes LLaMA Input (Detailed Logic + Safeguards)

ğŸ¯ Purpose

To ensure that every memory summary passed to LLaMA is:

Formatted consistently

Cleaned and trimmed for context limits

Checked for prior processing to avoid duplication

Logged with full trace metadata

Stored in a predictable path (llama/input.txt)

Ready for structured JSON output from LLaMA

ğŸ›  Workflow

Trigger: ChatGPT or save manager reaches Step 2 in bop

Source Text: GPT selects and chunks recent conversation (~3,000 tokens max)

Hashing: SHA256 hash generated from content

Deduplication Check: If input_hash.json contains the hash â†’ skip LLaMA

Template Fill: Chunks inserted into summarize_and_tag.txt

Metadata Inject: Add chat_name, message_id, and input_hash into the input text

Write File: Final prompt saved to path from paths.json

âœ… Required Files

summarize_and_tag.txt â†’ Contains the formatting and instructions for LLaMA

llama/input.txt â†’ File that LLaMA reads from (path configurable)

input_hash.json â†’ Tracks previously processed chunks

paths.json â†’ Central path configuration

ğŸ”§ Failures + Fixes

âŒ Missing or Corrupted Template

âœ… Use inline fallback template

âœ… Templates are versioned: v1, v2, default

âœ… SHA checksum logged during use for integrity check

âŒ Wrong File Path

âœ… All paths pulled from paths.json

âœ… Validate file/directory existence before write

âœ… Log path failures to path_errors.log

âŒ Duplicate Input Reprocessing

âœ… GPT calculates content hash

âœ… If hash is in input_hash.json, input is skipped

âœ… Otherwise, hash and metadata are logged before execution

âŒ Old Inputs Not Cleared

âœ… Each run truncates file and writes a timestamp header:

# GENERATED ON: YYYY-MM-DD HH:MM

âŒ Unescaped Characters / Markdown Breaks Prompt

âœ… Sanitizer replaces smart quotes and escapes special characters

âŒ Overlong Prompt (LLaMA Limit)

âœ… GPT limits chunks to ~3,000 tokens

âœ… Optional validate_prompt_length.py logs overflow risk

ğŸ§ª Example: Final Prompt Written to File

# GENERATED ON: 2025-04-23
CHAT: GPT Memory Build
MSG_ID: msg_472-20
HASH: a7b2e34...

INSTRUCTION:
Summarize and tag the following conversation.

GOAL:
Extract insights, remove noise, and tag the entry.

CONTENT:
[user's chunked memory input here]

ğŸ§  Future Expansion

Allow multiple input formats (e.g. tag-first, summarize-only)

Use prompt variants for testing different summarization styles

Automate hash deduplication reporting for audit purposes

Module: Step 2 â€” GPT â LLaMA Prompt WriterOwned by: ChatGPT OrchestratorLast Updated: 2025-04-23

